import openai
import pandas as pd
import json
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
from .text_pdf_processor import process_text_file, analyze_text_data_structure

# Initialize OpenAI client
def get_openai_client():
    """Get OpenAI client with API key from environment"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY environment variable is not set")
    return openai.OpenAI(api_key=api_key)

def read_data(file_path: str) -> pd.DataFrame:
    """Read data from various file formats including text and PDF"""
    from pathlib import Path
    
    # Resolve absolute path if relative path is provided
    path_obj = Path(file_path)
    if not path_obj.is_absolute():
        # Try to resolve relative to current working directory
        path_obj = Path.cwd() / file_path
    
    if not path_obj.exists():
        raise FileNotFoundError(f"File not found: {file_path}")
    
    file_extension = path_obj.suffix.lower()
    if file_extension == '.csv':
        return pd.read_csv(str(path_obj))
    elif file_extension in ['.xlsx', '.xls']:
        return pd.read_excel(str(path_obj))
    elif file_extension in ['.pdf', '.txt', '.docx']:
        return process_text_file(str(path_obj))
    else:
        raise ValueError(f"Unsupported file format: {file_extension}")

def analyze_data_structure(data: pd.DataFrame, file_path: str = None) -> Dict[str, Any]:
    """Analyze the structure and characteristics of the data"""
    analysis = {
        'shape': data.shape,
        'columns': list(data.columns),
        'numeric_columns': data.select_dtypes(include=['number']).columns.tolist(),
        'categorical_columns': data.select_dtypes(include=['object', 'category']).columns.tolist(),
        'datetime_columns': data.select_dtypes(include=['datetime64']).columns.tolist(),
        'missing_values': data.isnull().sum().to_dict(),
        'sample_data': data.head(3).to_dict('records')
    }
    
    # Add file type information
    if file_path:
        file_extension = file_path.split('.')[-1].lower()
        analysis['file_type'] = file_extension
        analysis['is_text_derived'] = file_extension in ['pdf', 'txt', 'docx']
    
    return analysis

def process_data_with_llm(data: pd.DataFrame, user_prompt: str = "", file_path: str = "") -> Dict[str, Any]:
    """
    Main function: Send extracted data + user prompt to LLM, get back analysis + Recharts JSON
    This is the core of the new simplified system
    """
    try:
        # Detect user language
        def detect_language(text: str) -> str:
            cyrillic_chars = sum(1 for c in text if '\u0400' <= c <= '\u04FF')
            return "ru" if cyrillic_chars > 0 else "en"
        
        user_language = detect_language(user_prompt) if user_prompt else "ru"
        
        # Prepare data summary for LLM
        data_info = {
            'shape': data.shape,
            'columns': list(data.columns),
            'numeric_columns': data.select_dtypes(include=['number']).columns.tolist(),
            'categorical_columns': data.select_dtypes(include=['object', 'category']).columns.tolist(),
            'datetime_columns': data.select_dtypes(include=['datetime64']).columns.tolist(),
            'sample_data': data.head(5).to_dict('records'),
            'data_types': {col: str(dtype) for col, dtype in data.dtypes.items()},
            'unique_values': {col: int(data[col].nunique()) for col in data.columns},
            'null_counts': data.isnull().sum().to_dict()
        }
        
        # Add statistics for numeric columns
        numeric_stats = {}
        for col in data_info['numeric_columns']:
            if col in data.columns:
                numeric_stats[col] = {
                    'min': float(data[col].min()),
                    'max': float(data[col].max()),
                    'mean': float(data[col].mean()),
                    'median': float(data[col].median()),
                    'std': float(data[col].std()) if data[col].std() == data[col].std() else 0  # Handle NaN
                }
        data_info['numeric_stats'] = numeric_stats
        
        # Create comprehensive prompt for LLM
        if user_language == "ru":
            system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞:

1. –ê–ù–ê–õ–ò–ó–ò–†–û–í–ê–¢–¨ –¥–∞–Ω–Ω—ã–µ –∏ –ø–æ–Ω–∏–º–∞—Ç—å —á—Ç–æ –æ–Ω–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç
2. –í–´–ü–û–õ–ù–Ø–¢–¨ –∑–∞–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞, –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, –≤—ã–±–æ—Ä —Ç–∏–ø–∞ –≥—Ä–∞—Ñ–∏–∫–∞)
3. –°–û–ó–î–ê–í–ê–¢–¨ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è Recharts
4. –î–ê–í–ê–¢–¨ –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ

–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∏–ø—ã –≥—Ä–∞—Ñ–∏–∫–æ–≤:
- BarChart: –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —Å—Ä–∞–≤–Ω–µ–Ω–∏–π
- LineChart: –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤, —Ç—Ä–µ–Ω–¥–æ–≤
- AreaChart: –¥–ª—è –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- PieChart: –¥–ª—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–π (–¥–æ 8 –∫–∞—Ç–µ–≥–æ—Ä–∏–π)
- ScatterChart: –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –º–µ–∂–¥—É —á–∏—Å–ª–æ–≤—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
- RadarChart: –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π
- ComposedChart: –¥–ª—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π

–í–ê–ñ–ù–û: 
- –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É/–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø—Ä–∏–º–µ–Ω–∏ —ç—Ç–æ –∫ –¥–∞–Ω–Ω—ã–º
- –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞ - –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ
- –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –ø–æ–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ - –∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö
- –í–æ–∑–≤—Ä–∞—â–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ markdown –±–ª–æ–∫–æ–≤

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
{
    "chartType": "—Ç–∏–ø_–≥—Ä–∞—Ñ–∏–∫–∞",
    "data": [–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ_–¥–∞–Ω–Ω—ã–µ_—Å_—É—á–µ—Ç–æ–º_–∑–∞–ø—Ä–æ—Å–∞],
    "config": {
        "xKey": "–∫–æ–ª–æ–Ω–∫–∞_X",
        "yKey": "–∫–æ–ª–æ–Ω–∫–∞_Y_–∏–ª–∏_–º–∞—Å—Å–∏–≤",
        "title": "–ó–∞–≥–æ–ª–æ–≤–æ–∫ –≥—Ä–∞—Ñ–∏–∫–∞",
        "xLabel": "–ü–æ–¥–ø–∏—Å—å X",
        "yLabel": "–ü–æ–¥–ø–∏—Å—å Y",
        "colors": ["#8884d8", "#82ca9d", "#ffc658"]
    },
    "analyticalText": "–ö—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –≥—Ä–∞—Ñ–∏–∫–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ"
}"""
            
            if user_prompt:
                user_message = f"""
–î–ê–ù–ù–´–ï:
–†–∞–∑–º–µ—Ä: {data_info['shape']} —Å—Ç—Ä–æ–∫ –∏ —Å—Ç–æ–ª–±—Ü–æ–≤
–ö–æ–ª–æ–Ω–∫–∏: {data_info['columns']}
–ß–∏—Å–ª–æ–≤—ã–µ: {data_info['numeric_columns']}
–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ: {data_info['categorical_columns']}
–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {data_info['numeric_stats']}

–ü–†–ò–ú–ï–†–´ –î–ê–ù–ù–´–•:
{json.dumps(data_info['sample_data'], indent=2, ensure_ascii=False)}

–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: "{user_prompt}"

–û–±—Ä–∞–±–æ—Ç–∞–π –¥–∞–Ω–Ω—ã–µ —Å–æ–≥–ª–∞—Å–Ω–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Å–æ–∑–¥–∞–π –ø–æ–¥—Ö–æ–¥—è—â—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é.
"""
            else:
                user_message = f"""
–î–ê–ù–ù–´–ï:
–†–∞–∑–º–µ—Ä: {data_info['shape']} —Å—Ç—Ä–æ–∫ –∏ —Å—Ç–æ–ª–±—Ü–æ–≤
–ö–æ–ª–æ–Ω–∫–∏: {data_info['columns']}
–ß–∏—Å–ª–æ–≤—ã–µ: {data_info['numeric_columns']}
–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ: {data_info['categorical_columns']}
–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {data_info['numeric_stats']}

–ü–†–ò–ú–ï–†–´ –î–ê–ù–ù–´–•:
{json.dumps(data_info['sample_data'], indent=2, ensure_ascii=False)}

–°–æ–∑–¥–∞–π –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –¥–ª—è —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
"""
        else:
            system_prompt = """You are an expert in data analysis and visualization. Your task:

1. ANALYZE data and understand what it shows
2. EXECUTE user requests (sorting, grouping, filtering, chart type selection)
3. CREATE proper Recharts configuration
4. PROVIDE brief analysis in English

Available chart types:
- BarChart: for categorical data, comparisons
- LineChart: for time series, trends
- AreaChart: for cumulative data
- PieChart: for proportions (up to 8 categories)
- ScatterChart: for correlations between numeric variables
- RadarChart: for multi-dimensional comparisons
- ComposedChart: for combined visualizations

IMPORTANT:
- If user asks for sorting/grouping - MUST apply it to data
- If user asks for specific chart type - use it
- If user asks to show specific columns - use them
- Return ONLY valid JSON without markdown blocks

Response format:
{
    "chartType": "chart_type",
    "data": [processed_data_according_to_request],
    "config": {
        "xKey": "x_column",
        "yKey": "y_column_or_array",
        "title": "Chart title",
        "xLabel": "X label",
        "yLabel": "Y label",
        "colors": ["#8884d8", "#82ca9d", "#ffc658"]
    },
    "analyticalText": "Brief analysis of data and chart in English"
}"""
            
            if user_prompt:
                user_message = f"""
DATA:
Size: {data_info['shape']} rows and columns
Columns: {data_info['columns']}
Numeric: {data_info['numeric_columns']}
Categorical: {data_info['categorical_columns']}
Statistics: {data_info['numeric_stats']}

SAMPLE DATA:
{json.dumps(data_info['sample_data'], indent=2)}

USER REQUEST: "{user_prompt}"

Process the data according to user request and create appropriate visualization.
"""
            else:
                user_message = f"""
DATA:
Size: {data_info['shape']} rows and columns
Columns: {data_info['columns']}
Numeric: {data_info['numeric_columns']}
Categorical: {data_info['categorical_columns']}
Statistics: {data_info['numeric_stats']}

SAMPLE DATA:
{json.dumps(data_info['sample_data'], indent=2)}

Create the most appropriate visualization for this data.
"""
        
        # Call OpenAI API
        client = get_openai_client()
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            max_tokens=2000,
            temperature=0.2
        )
        
        config_text = response.choices[0].message.content.strip()
        
        # Clean JSON response
        if config_text.startswith('```json'):
            config_text = config_text[7:]
        if config_text.startswith('```'):
            config_text = config_text[3:]
        if config_text.endswith('```'):
            config_text = config_text[:-3]
        
        # Parse JSON
        result = json.loads(config_text)
        
        # If LLM didn't provide processed data, use original data
        if not result.get('data'):
            result['data'] = data.to_dict('records')
        
        # Process data according to user request if LLM provided processed data
        if result.get('data') and isinstance(result['data'], list):
            # Convert back to DataFrame for any additional processing
            processed_df = pd.DataFrame(result['data'])
            
            # Apply user requests to data if not already handled by LLM
            if user_prompt and processed_df.shape == data.shape:
                processed_df = apply_user_requests_to_data(data, user_prompt)
                result['data'] = processed_df.to_dict('records')
        
        print(f"‚úÖ LLM processed data successfully: {len(result['data'])} records")
        return result
            
    except Exception as e:
        print(f"‚ùå Error in LLM processing: {e}")
        # Fallback to simple processing
        return create_fallback_visualization(data, user_prompt, user_language)

def apply_user_requests_to_data(data: pd.DataFrame, user_prompt: str) -> pd.DataFrame:
    """Apply user requests like sorting, grouping, filtering to data"""
    try:
        processed_data = data.copy()
        prompt_lower = user_prompt.lower()
        
        # Handle sorting requests
        if any(word in prompt_lower for word in ['—Å–æ—Ä—Ç–∏—Ä—É–π', '–æ—Ç—Å–æ—Ä—Ç–∏—Ä—É–π', 'sort', 'order']):
            # Find numeric columns for sorting
            numeric_cols = data.select_dtypes(include=['number']).columns.tolist()
            if numeric_cols:
                main_col = numeric_cols[0]
                if '—É–±—ã–≤' in prompt_lower or 'descend' in prompt_lower or '–±–æ–ª—å—à' in prompt_lower:
                    processed_data = processed_data.sort_values(main_col, ascending=False)
                else:
                    processed_data = processed_data.sort_values(main_col, ascending=True)
        
        # Handle grouping requests
        if any(word in prompt_lower for word in ['–≥—Ä—É–ø–ø', 'group', '–ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É', 'by count']):
            categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()
            if categorical_cols:
                group_col = categorical_cols[0]
                # Count occurrences
                grouped = processed_data.groupby(group_col).size().reset_index(name='Count')
                grouped = grouped.sort_values('Count', ascending=False)
                processed_data = grouped
        
        # Handle filtering requests
        if '—Ç–æ–ø' in prompt_lower or 'top' in prompt_lower:
            # Extract number
            import re
            numbers = re.findall(r'\d+', user_prompt)
            if numbers:
                n = int(numbers[0])
                processed_data = processed_data.head(n)
        
        return processed_data
        
    except Exception as e:
        print(f"Error applying user requests: {e}")
        return data

def create_fallback_visualization(data: pd.DataFrame, user_prompt: str, user_language: str) -> Dict[str, Any]:
    """Create fallback visualization when LLM fails"""
    try:
        # Apply user requests to data
        processed_data = apply_user_requests_to_data(data, user_prompt)
        
        # Determine chart type
        numeric_cols = processed_data.select_dtypes(include=['number']).columns.tolist()
        categorical_cols = processed_data.select_dtypes(include=['object', 'category']).columns.tolist()
        
        if len(categorical_cols) >= 1 and len(numeric_cols) >= 1:
            chart_type = "BarChart"
            x_key = categorical_cols[0]
            y_key = numeric_cols[0]
        elif len(numeric_cols) >= 2:
            chart_type = "ScatterChart"
            x_key = numeric_cols[0]
            y_key = numeric_cols[1]
        else:
            chart_type = "BarChart"
            x_key = list(processed_data.columns)[0]
            y_key = list(processed_data.columns)[1] if len(processed_data.columns) > 1 else list(processed_data.columns)[0]
        
        # Create config
        if user_language == "ru":
            title = f"–ì—Ä–∞—Ñ–∏–∫: {y_key} –ø–æ {x_key}"
            analytical_text = f"–°–æ–∑–¥–∞–Ω –≥—Ä–∞—Ñ–∏–∫ —Ç–∏–ø–∞ {chart_type} —Å {len(processed_data)} –∑–∞–ø–∏—Å—è–º–∏. –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç {y_key} –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç {x_key}."
        else:
            title = f"Chart: {y_key} by {x_key}"
            analytical_text = f"Created {chart_type} with {len(processed_data)} records. Shows {y_key} by {x_key}."
        
        return {
            "chartType": chart_type,
            "data": processed_data.to_dict('records'),
            "config": {
                "xKey": x_key,
                "yKey": y_key,
                "title": title,
                "xLabel": x_key,
                "yLabel": y_key,
                "colors": ["#8884d8", "#82ca9d", "#ffc658"]
            },
            "analyticalText": analytical_text
        }
        
    except Exception as e:
        print(f"Error in fallback visualization: {e}")
        return {
            "chartType": "BarChart",
            "data": data.to_dict('records'),
            "config": {
                "xKey": list(data.columns)[0],
                "yKey": list(data.columns)[1] if len(data.columns) > 1 else list(data.columns)[0],
                "title": "Data Visualization",
                "xLabel": "X",
                "yLabel": "Y",
                "colors": ["#8884d8", "#82ca9d", "#ffc658"]
            },
            "analyticalText": "Basic data visualization created."
        }

def create_intelligent_visualization(file_path: str, user_prompt: str = "") -> Dict[str, Any]:
    """
    Main function: Create visualization from file
    This replaces the old complex system with a simple: file -> data -> LLM -> result
    """
    try:
        # Step 1: Read data from file
        data = read_data(file_path)
        print(f"üìä Data loaded: {data.shape} rows x {data.shape[1]} columns")
        
        # Step 2: Process with LLM
        result = process_data_with_llm(data, user_prompt, file_path)
        
        print(f"‚úÖ Visualization created successfully")
        return result
        
    except Exception as e:
        print(f"‚ùå Error creating visualization: {e}")
        raise e

def customize_visualization(current_data: pd.DataFrame, user_prompt: str) -> Dict[str, Any]:
    """
    Customize existing visualization based on user prompt
    This is now much simpler - just process data with LLM using the prompt
    """
    try:
        # Convert DataFrame if needed
        if isinstance(current_data, list):
            current_data = pd.DataFrame(current_data)
        
        # Process with LLM
        result = process_data_with_llm(current_data, user_prompt)
        
        print(f"‚úÖ Visualization customized successfully")
        return result
        
    except Exception as e:
        print(f"‚ùå Error customizing visualization: {e}")
        raise e

# Legacy compatibility functions
def process_user_request(file_paths: List[str], user_message: str, current_data: pd.DataFrame = None, current_chart: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    Legacy function for backward compatibility
    Now uses the new simplified system
    """
    try:
        # Detect user language
        def detect_language(text: str) -> str:
            cyrillic_chars = sum(1 for c in text if '\u0400' <= c <= '\u04FF')
            return "ru" if cyrillic_chars > 0 else "en"
        
        user_language = detect_language(user_message)
        
        # Case 1: New file uploaded
        if file_paths:
            file_path = file_paths[0]
            chart_config = create_intelligent_visualization(file_path, user_message)
            
            # Store data for future use
            data = read_data(file_path)
            
            file_name = os.path.basename(file_path)
            analytical_text = chart_config.get('analyticalText', '')
            
            if user_language == "ru":
                response_text = f"‚úÖ –°–æ–∑–¥–∞–ª –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞ {file_name}.\n\n{analytical_text}\n\nüí° –ú–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ—Å–∏—Ç—å –∏–∑–º–µ–Ω–∏—Ç—å —Ç–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞, —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É, —Ñ–∏–ª—å—Ç—Ä—ã –∏ —Ç.–¥."
            else:
                response_text = f"‚úÖ Created visualization from file {file_name}.\n\n{analytical_text}\n\nüí° You can ask to change chart type, sorting, filters, etc."
            
            return {
                "answer": response_text,
                "type": "data_analysis",
                "confidence": 0.9,
                "sources": [file_name],
                "timestamp": datetime.utcnow().isoformat(),
                "visualization": chart_config,
                "current_data": data.to_dict('records'),
                "success": True
            }
        
        # Case 2: Customize existing chart
        elif current_data is not None:
            new_chart_config = customize_visualization(current_data, user_message)
            
            analytical_text = new_chart_config.get('analyticalText', '')
            
            if user_language == "ru":
                response_text = f"‚úÖ –û–±–Ω–æ–≤–∏–ª –≥—Ä–∞—Ñ–∏–∫: \"{user_message}\"\n\n{analytical_text}"
            else:
                response_text = f"‚úÖ Updated chart: \"{user_message}\"\n\n{analytical_text}"
            
            return {
                "answer": response_text,
                "type": "data_analysis",
                "confidence": 0.9,
                "sources": [],
                "timestamp": datetime.utcnow().isoformat(),
                "visualization": new_chart_config,
                "current_data": current_data if isinstance(current_data, list) else current_data.to_dict('records'),
                "success": True
            }
        
        # Case 3: General chat
        else:
            if user_language == "ru":
                response_text = "–ü—Ä–∏–≤–µ—Ç! üëã –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª, –∏ —è —Å–æ–∑–¥–∞–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é. –ó–∞—Ç–µ–º –º–æ–∂–µ—Ç–µ –ø—Ä–æ—Å–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è."
            else:
                response_text = "Hello! üëã Upload a file and I'll create a visualization. Then you can ask for changes."
            
            return {
                "answer": response_text,
                "type": "general",
                "confidence": 0.8,
                "sources": [],
                "timestamp": datetime.utcnow().isoformat(),
                "success": True
            }
            
    except Exception as e:
        print(f"‚ùå Error processing user request: {e}")
        
        user_language = "ru" if sum(1 for c in user_message if '\u0400' <= c <= '\u04FF') > 0 else "en"
        
        if user_language == "ru":
            error_text = f"–û—à–∏–±–∫–∞: {str(e)}"
        else:
            error_text = f"Error: {str(e)}"
        
        return {
            "answer": error_text,
            "type": "error",
            "confidence": 0.0,
            "sources": [],
            "timestamp": datetime.utcnow().isoformat(),
            "success": False
        }

def main(file_path: str):
    """Legacy main function for backward compatibility"""
    return create_intelligent_visualization(file_path)